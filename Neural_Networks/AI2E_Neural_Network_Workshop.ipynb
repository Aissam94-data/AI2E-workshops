{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI2E_Neural_Network_Workshop.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8YthVz12tvD",
        "colab_type": "text"
      },
      "source": [
        "#what is a deep learning framework ?\n",
        "A Deep Learning is simply a tool or an interface, that makes us able to build, manage and use Deep Learning models, such as Neural Networks. It can be low-level, which means that the programmer can intervene on the Model structure in detail, or high-level which gives more abstraction in the management.\n",
        "\n",
        "#Some DL frameworks\n",
        "TensorFlow, PyTorch, Keras, Sonnet, MXnet...\n",
        "\n",
        "About PyTorch :\n",
        "Intially developed for Facebook services but is already used for its own tasks by companies like Twitter. Based on Torch library, PyTorch deals with \"Tensors\", which are just some kind of arrays, that can tap into the resources of a GPU (Graphic Processing Unit) to significantly speed up matrix operations. To accelerate the process in another way, PyTorch has the Autograd Module, which makes it able to use Automatic Differentiation, that can computes the derivative of the loss function is a very faster way.\n",
        "\n",
        "#Pytorch vs TensorFlow\n",
        "In Tensorflow, you first have to define the entire computation graph of the model and then run your ML model. But in PyTorch, you can define & manipulate your graph on-the-go. Also, PyTorch is very *pythonic* : It uses the style and powers of python, which makes it much easier and simpler to understand and use. Especially for Python coders. In Tensorflow, you need to learn a lot of *Tensorflow-specific jargon*.\n",
        "\n",
        "\\\n",
        "In this tutorial, we're gonna build a standard Neural Network, using PyTorch, to recognize hand written digits in the famous MNIST dataset. We're gonna see how can the choice of the activation function, batch size, epochs number...and other parameters influence the efficiency of our model.\n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afRHHr5OcPHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4VrGdkjHVrb",
        "colab_type": "text"
      },
      "source": [
        "#Mnist dataset\n",
        "MNIST is a large database of handwritten digits that is commonly used for training various image processing systems. It contains 60,000 training images and 10,000 testing images.  In the original paper, the authors use a support-vector machine to get an error rate of 0.8%.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGNaNhByF6b_",
        "colab_type": "code",
        "outputId": "58d47c24-ddbc-4bf1-c384-8608fd030646",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define a transform to convert the data to pytorch's tensor object\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "# Download and load the training data\n",
        "dataset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "\n",
        "images = dataset.data.float()\n",
        "classes = dataset.classes\n",
        "labels = dataset.targets\n",
        "\n",
        "print(type(images))\n",
        "print(images.shape)\n",
        "print(classes, \"\\n num classes : \", len(classes))\n",
        "print(labels.shape)\n",
        "\n",
        "img = 1\n",
        "plt.title(classes[labels[img]])\n",
        "plt.imshow(images[img].numpy().squeeze(), cmap='Greys_r')"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.Size([60000, 28, 28])\n",
            "['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine'] \n",
            " num classes :  10\n",
            "torch.Size([60000])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fe822e8c208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unb97kWTNSLa",
        "colab_type": "text"
      },
      "source": [
        "#network definition in Pytorch\n",
        "Neural networks can be constructed using the torch.nn package. We just have to define the forward function, and the backward function (where gradients are computed) is automatically defined for you using autograd. You can use any of the Tensor operations in the forward function.\n",
        "\n",
        "- if possible, a graphical representation of the implemented neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JOJQEWGcZHX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Weights matrix for hidden layer 1\n",
        "        self.W_1 = nn.Parameter(torch.Tensor(input_layer_size, output_layer_size))\n",
        "        self.b_1 = nn.Parameter(torch.Tensor(input_layer_size, output_layer_size))\n",
        "        #Alternatively \n",
        "        # Inputs to hidden layer 1 linear transformation\n",
        "        #self.hidden = nn.Linear(layer_input_size, layer_output_size)\n",
        "\n",
        "        # Weights matrix for hidden layer 2\n",
        "        self.W_2 = nn.Parameter(torch.Tensor(input_layer_size, output_layer_size))\n",
        "        self.b_2 = nn.Parameter(torch.Tensor(input_layer_size, output_layer_size))\n",
        "        #Alternatively \n",
        "        # Inputs to hidden layer 2 linear transformation\n",
        "        #self.hidden = nn.Linear(layer_input_size, layer_output_size)\n",
        "\n",
        "        # Weights matrix for out layer\n",
        "        self.W_out = nn.Parameter(torch.Tensor(input_layer_size, output_layer_size))\n",
        "        self.b_out = nn.Parameter(torch.Tensor(input_layer_size, output_layer_size))\n",
        "        #Alternatively\n",
        "        # Output layer\n",
        "        #self.output = nn.Linear(ayer_input_size, layer_output_size)\n",
        "        self.init_params()\n",
        "      \n",
        "    def init_params(self):\n",
        "      self.W_1.data.normal_(std=0.01)\n",
        "      self.b_1.data.fill_(0)\n",
        "      self.W_2.data.normal_(std=0.01)\n",
        "      self.b_2.data.fill_(0)\n",
        "      self.W_out.data.normal_(std=0.01)\n",
        "      self.b_out.data.fill_(0)\n",
        "\n",
        "    def forward(self, x, log=False):\n",
        "        if log :\n",
        "          print(\"=======forward pass=======\")\n",
        "          print(\"data on input layer\")\n",
        "          plt.imshow(x.contiguous().detach().view(28,28).numpy(), cmap='Greys_r')\n",
        "          plt.show()\n",
        "        # Hidden layer 1 with sigmoid activation\n",
        "        x = torch.matmul(x, self.W_1)\n",
        "        x = x + self.b_1\n",
        "        if log :\n",
        "          print(\"data after layer 1 forward function\")\n",
        "          plt.imshow(x.contiguous().detach().view(16,16).numpy(), cmap='Greys_r')\n",
        "          plt.show()\n",
        "\n",
        "        x = F.sigmoid(x)\n",
        "        if log :\n",
        "          print(\"data after layer 1 activation function\")\n",
        "          plt.imshow(x.contiguous().detach().view(16,16).numpy(), cmap='Greys_r')\n",
        "          plt.show()\n",
        "        #Alternatively\n",
        "        #x = F.sigmoid(self.hidden(x))\n",
        "\n",
        "        # Hidden layer 2 with sigmoid activation\n",
        "        x = torch.matmul(x, self.W_2)\n",
        "        x = x + self.b_2\n",
        "        if log :\n",
        "          print(\"data after layer 2 forward function\")\n",
        "          plt.imshow(x.contiguous().detach().view(8,8).numpy(), cmap='Greys_r')\n",
        "          plt.show()\n",
        "        \n",
        "        x = F.sigmoid(x)\n",
        "        if log :\n",
        "          print(\"data after layer 2 activation function\")\n",
        "          plt.imshow(x.contiguous().detach().view(8,8).numpy(), cmap='Greys_r')\n",
        "          plt.show()\n",
        "        #Alternatively\n",
        "        #x = F.sigmoid(self.hidden(x))\n",
        "        \n",
        "        x = torch.matmul(x, self.W_out)\n",
        "        x = x + self.b_out\n",
        "        if log :\n",
        "          print(\"data after out layer forward function\")\n",
        "          plt.imshow(x.contiguous().detach().numpy(), cmap='Greys_r')\n",
        "          plt.show()\n",
        "        \n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        #Alternatively\n",
        "        # Output layer with softmax activation\n",
        "        #x = F.log_softmax(self.output(x), dim=1)\n",
        "        \n",
        "        return x\n",
        "\n",
        "model = Network()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdxLKB0Y7thO",
        "colab_type": "text"
      },
      "source": [
        "#how to feed an image to a neural network ?\n",
        "An image is actually a series of individual color pixels, where each color pixel is actuall made up of a mix of three colors. So, we can consider an image just as a matrix of numbers. This matrix is transformed into an array and it will feed the Neural Network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8v85bJ6em3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = images[1]\n",
        "x.resize_(1, 784)\n",
        "proba = model.forward(x, log=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJQIsfvmecsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(proba)\n",
        "value, index = proba.max(1)\n",
        "\n",
        "print(\"image of classe {} at {:2f}%\".format(classes[index],value.data[0]*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J46zc6CDfznj",
        "colab_type": "text"
      },
      "source": [
        "**Learning Rate** : configurable hyperparameter used in the training of neural networks that has a small positive value, often in the range between 0.0 and 1.0. The learning rate controls how quickly the model is adapted to the problem.\\\n",
        "**Optimizer** : Package implementing various optimization algorithms. It will be used to optimize the gradients by tuning the Model parameters.\\\n",
        "**Nllloss** : The negative log likelihood loss. We use it to train the model for a classification problem with C classes.\\\n",
        "**Epochs** : Hyperparameter that indicates the number of passes through the entire training dataset the machine learning algorithm has completed.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NET_eIPHewbm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
        "\n",
        "# Define the loss\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "##one step on learning process\n",
        "# Flatten images\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "# Clear the gradients, do this because gradients are accumulated\n",
        "optimizer.zero_grad()\n",
        "# Forward pass, get our logits\n",
        "proba = model(images)\n",
        "# Calculate the loss with the logits and the labels\n",
        "loss = criterion(proba, labels)\n",
        "\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "#########\n",
        "\n",
        "def train(model, optimizer, criterion, images, labels):\n",
        "  epochs = 5\n",
        "  loss_hist = []\n",
        "  for e in range(epochs):\n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      output = model(images)\n",
        "      loss = criterion(output, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "          \n",
        "      loss_hist.append(loss.item())\n",
        "\n",
        "  plt.plot(loss_hist)\n",
        "  plt.ylabel(\"loss\")\n",
        "  plt.xlabel(\"epochs\")\n",
        "  plt.title(\"loss per epoch\")\n",
        "  plt.show()\n",
        "train(model, optimizer, criterion, images, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvQj5bMCe7zG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate the Model\n",
        "def view_classify(img, ps, version=\"MNIST\"):\n",
        "    ''' Function for viewing an image and it's predicted classes.\n",
        "    '''\n",
        "    ps = ps.data.numpy().squeeze()\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
        "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
        "    ax1.axis('off')\n",
        "    ax2.barh(np.arange(10), ps)\n",
        "    ax2.set_aspect(0.1)\n",
        "    ax2.set_yticks(np.arange(10))\n",
        "    if version == \"MNIST\":\n",
        "        ax2.set_yticklabels(np.arange(10))\n",
        "    elif version == \"Fashion\":\n",
        "        ax2.set_yticklabels(['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine'] , size='small');\n",
        "    ax2.set_title('Class Probability')\n",
        "    ax2.set_xlim(0, 1.1)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "def evaluate(model, images):\n",
        "  # Get images from test set\n",
        "  test_images = images\n",
        "  # Prepare the input data\n",
        "  img = test_images.view(n_images, -1)\n",
        "  # Use the model to predict the images class\n",
        "  with torch.no_grad():\n",
        "      proba = model(img)\n",
        "  proba = torch.exp(proba)\n",
        "  # Display\n",
        "  for i in range(n_images):\n",
        "      view_classify(img[i].view(1, 28, 28), proba[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aePiEbS3fAgw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict single images\n",
        "n_images = 10\n",
        "evaluate(model, images[:n_images])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UrcUt0aISrG",
        "colab_type": "text"
      },
      "source": [
        "#Using Batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyzJCBbWfETh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "batch_size = 64\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "model = Network()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
        "\n",
        "# Define the loss\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "def train(model, optimizer, criterion, trainloader):\n",
        "  epochs = 5\n",
        "  loss_hist = []\n",
        "  acc_hist = []\n",
        "  for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    accuracy = 0\n",
        "    for images, labels in trainloader:\n",
        "        # Flatten MNIST images into a 784 long vector\n",
        "        images = images.view(images.shape[0], -1)\n",
        "\n",
        "        # TODO: Training pass\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    \n",
        "        top_p, top_class = torch.exp(output).topk(1, dim=1)\n",
        "        equals = top_class == labels.view(*top_class.shape)\n",
        "        accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "        \n",
        "    acc_hist.append(accuracy/len(trainloader))\n",
        "    loss_hist.append(running_loss/len(trainloader))\n",
        "\n",
        "  plt.plot(loss_hist)\n",
        "  plt.ylabel(\"loss\")\n",
        "  plt.xlabel(\"epochs\")\n",
        "  plt.title(\"loss per epoch\")\n",
        "  plt.show()\n",
        "  plt.plot(acc_hist)\n",
        "  plt.ylabel(\"acc\")\n",
        "  plt.xlabel(\"epochs\")\n",
        "  plt.title(\"acc per epoch\")\n",
        "  plt.show()\n",
        "train(model, optimizer, criterion, trainloader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVplMo8FoG8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict single images\n",
        "n_images = 10\n",
        "images, labels = next(iter(trainloader))\n",
        "evaluate(model, images[:n_images])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M92YTOb2G2L0",
        "colab_type": "text"
      },
      "source": [
        "#What if we normalize the data ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4bEnRPtIKHM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.5,), (0.5,)),\n",
        "                              ])\n",
        "\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "model = Network()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
        "\n",
        "# Define the loss\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "train(model, optimizer, criterion, trainloader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbIbkCi6odqz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict single images\n",
        "n_images = 10\n",
        "images, labels = next(iter(trainloader))\n",
        "evaluate(model, images[:n_images])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YrzoiXHokS1",
        "colab_type": "text"
      },
      "source": [
        "**Split** : Process of splitting the whole data into train and test set. The train set will be feeded to the Model for the training, and the latter will be tested with the testing set.\\\n",
        "**Validation** : Process where the trained model is evaluated with a testing data set. This step comes after the training is completed.\\\n",
        "**Accuracy** : The measurement used to determine which model is best at identifying relationships and patterns between variables in a dataset based on the input data.\n"
      ]
    }
  ]
}